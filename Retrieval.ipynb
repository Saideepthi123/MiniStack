{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SAI\n",
      "[nltk_data]     DEEPTHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import threading\n",
    "from nltk.corpus import wordnet\n",
    "import time\n",
    "from multiprocessing import Process, Queue\n",
    "import multiprocessing\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import csv \n",
    "import requests \n",
    "import xml.etree.ElementTree as ET \n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "from nltk.stem.porter import *\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, Manager\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_pickle(\"Preprocessed_questions_text.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (161327, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>non_stopword_removed_preprocessed_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Besides being \"one of the 7 meta questions ...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>besides being one of the 7 meta questions ever...</td>\n",
       "      <td>besides one 7 meta questions every site ask pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I've clicked on &lt;em&gt;chat&lt;/em&gt; link, but the...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>i have clicked on chat link but the list is em...</td>\n",
       "      <td>clicked chat link list empty also tried create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I think this will be a crucial thing to fig...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>i think this will be a crucial thing to figure...</td>\n",
       "      <td>think crucial thing figure one hand think impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Are all questions asked on stats and data s...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>are all questions asked on stats and data scie...</td>\n",
       "      <td>questions asked stats data science se also top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;I've seen several questions that use the &lt;a...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>i have seen several questions that use the art...</td>\n",
       "      <td>seen several questions use artificialintellige...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id                                               Text    Topic  \\\n",
       "0  0  <p>Besides being \"one of the 7 meta questions ...  /AImeta   \n",
       "1  1  <p>I've clicked on <em>chat</em> link, but the...  /AImeta   \n",
       "2  2  <p>I think this will be a crucial thing to fig...  /AImeta   \n",
       "3  3  <p>Are all questions asked on stats and data s...  /AImeta   \n",
       "4  4  <p>I've seen several questions that use the <a...  /AImeta   \n",
       "\n",
       "              non_stopword_removed_preprocessed_text  \\\n",
       "0  besides being one of the 7 meta questions ever...   \n",
       "1  i have clicked on chat link but the list is em...   \n",
       "2  i think this will be a crucial thing to figure...   \n",
       "3  are all questions asked on stats and data scie...   \n",
       "4  i have seen several questions that use the art...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  besides one 7 meta questions every site ask pl...  \n",
       "1  clicked chat link list empty also tried create...  \n",
       "2  think crucial thing figure one hand think impo...  \n",
       "3  questions asked stats data science se also top...  \n",
       "4  seen several questions use artificialintellige...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape\", total_df.shape)\n",
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_text (161327,)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = total_df['preprocessed_text']\n",
    "print(\"preprocessed_text\", preprocessed_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(total_df['non_stopword_removed_preprocessed_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((161327, 487664), (161327, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "with open('glove_vectors', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    glove_words =  set(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_w2v_vectors_tr = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in total_df['non_stopword_removed_preprocessed_text'].values: # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    avg_w2v_vectors_tr.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "300\n",
      "--- 79.11199069023132 seconds ---\n",
      "what is the definition of artificial intelligence\n",
      "*************************************************************************************************************\n",
      "artificial intelligence a modern approach \n",
      "*************************************************************************************************************\n",
      "what is the difference between artificial intelligence and robots\n",
      "*************************************************************************************************************\n",
      "how is artificial intelligence different from machine learning\n",
      "*************************************************************************************************************\n",
      "what are good alternatives to the expression artificial intelligence good answers will not list names at random they will give a rationale for why their alternative name is a good oneing human intelligence which is not actually what artificial intelligence is\n",
      "*************************************************************************************************************\n",
      "for questions related to symbolic artificial intelligence which is also known as good oldfashioned artificial intelligence gofai which is an expression coined by john haugeland in his 1985 book artificial intelligence the very idea\n",
      "*************************************************************************************************************\n",
      "would an artificial general intelligence have to be turing completeat could successfully perform any intellectual task that a human being can\n",
      "*************************************************************************************************************\n",
      "it is apparently used to find patterns in data and it is loosely inspired by human neural networks\n",
      "*************************************************************************************************************\n",
      "what impact will artificial intelligence have on human society\n",
      "*************************************************************************************************************\n",
      "how can artificial intelligence be applied to software testing  \n",
      "*************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sentence = \"What is artifical intelligence\" # Serach Query\n",
    "avg_w2v_vectors_cv = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "vector = np.zeros(300) # as word vectors are of zero length\n",
    "cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "for word in sentence.split(): # for each word in a review/sentence\n",
    "    if word in glove_words:\n",
    "        vector += model[word]\n",
    "        cnt_words += 1\n",
    "if cnt_words != 0:\n",
    "    vector /= cnt_words\n",
    "avg_w2v_vectors_cv.append(vector)\n",
    "\n",
    "print(len(avg_w2v_vectors_cv))\n",
    "print(len(avg_w2v_vectors_cv[0]))\n",
    "\n",
    "\n",
    "#########################################################################################################################################\n",
    "doc_dict = dict()\n",
    "for i in range(len(avg_w2v_vectors_tr)):\n",
    "    doc_dict[i] = cosine_similarity([avg_w2v_vectors_tr[i]], avg_w2v_vectors_cv)\n",
    "    \n",
    "a = sorted(doc_dict.items(), key=lambda x: x[1], reverse=True) [:10]\n",
    "\n",
    "##############################################################################################\n",
    "top_items = []\n",
    "#a[0][0]\n",
    "for i in range(10):\n",
    "    top_items.append(a[i][0])\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "################################################################################################\n",
    "for index in top_items:\n",
    "    print (total_df.iloc[index,3])\n",
    "    print(\"*************************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "300\n",
      "--- 34.91248536109924 seconds ---\n",
      "is \\omega \\left\\fracn\\logn \\right\\subset \\tilde\\omegan \n",
      "*************************************************************************************************************\n",
      "\\lognk is const \\implies 2^\\lognk is const \\implies o2^k \\cdot logn  o2^\\lognk \\cdot 2^k \\cdot logn  o2^\\logn \\cdot logn  on \\cdot logn\n",
      "*************************************************************************************************************\n",
      "it is usually represented as hk\n",
      "*************************************************************************************************************\n",
      "is there an undecidable problem which is not nphard\n",
      "*************************************************************************************************************\n",
      "if the solution is stipulated to be unique is max2sat still npcomplete\n",
      "*************************************************************************************************************\n",
      "suppose that l is a contextsensitive language which is not contextfree then l\\\\epsilon\\ is not contextfree here \\epsilon is the empty word while l\\emptyset is contextfree\n",
      "*************************************************************************************************************\n",
      "this is correct there is an epsilon production\n",
      "*************************************************************************************************************\n",
      "is karatsuba algorithm simple enough it is complexity is on^159\n",
      "*************************************************************************************************************\n",
      "it is called fourdimensional matching and it is npcomplete\n",
      "*************************************************************************************************************\n",
      "dijkstra is smoothsort comes close but is not stable\n",
      "*************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sentence = \"What is Computer Graphics\" # Serach Query\n",
    "avg_w2v_vectors_cv = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "vector = np.zeros(300) # as word vectors are of zero length\n",
    "cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "for word in sentence.split(): # for each word in a review/sentence\n",
    "    if word in glove_words:\n",
    "        vector += model[word]\n",
    "        cnt_words += 1\n",
    "if cnt_words != 0:\n",
    "    vector /= cnt_words\n",
    "avg_w2v_vectors_cv.append(vector)\n",
    "\n",
    "print(len(avg_w2v_vectors_cv))\n",
    "print(len(avg_w2v_vectors_cv[0]))\n",
    "\n",
    "\n",
    "#########################################################################################################################################\n",
    "doc_dict = dict()\n",
    "for i in range(len(avg_w2v_vectors_tr)):\n",
    "    doc_dict[i] = cosine_similarity([avg_w2v_vectors_tr[i]], avg_w2v_vectors_cv)\n",
    "    \n",
    "a = sorted(doc_dict.items(), key=lambda x: x[1], reverse=True) [:10]\n",
    "\n",
    "##############################################################################################\n",
    "top_items = []\n",
    "#a[0][0]\n",
    "for i in range(10):\n",
    "    top_items.append(a[i][0])\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "################################################################################################\n",
    "for index in top_items:\n",
    "    print (total_df.iloc[index,3])\n",
    "    print(\"*************************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
