{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BagofWords.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE8xfgsI6Fl9",
        "outputId": "33b97b19-fde5-458e-a893-9f90434447f2"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import math\n",
        "import threading\n",
        "from nltk.corpus import wordnet\n",
        "import time\n",
        "from multiprocessing import Process, Queue\n",
        "import multiprocessing\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import csv \n",
        "import requests \n",
        "import xml.etree.ElementTree as ET \n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "from nltk.stem.porter import *\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool, Manager\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbKyLJR26M2l"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(total_df['non_stopword_removed_preprocessed_text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Av_SZy6PsR"
      },
      "source": [
        "X.shape,total_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjviucxs6SUj"
      },
      "source": [
        "Query = \"What is artifical intelligence\"\n",
        "Query_Bow = vectorizer.transform([Query])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSAoMCuw6YW9"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "doc_dict = dict()\n",
        "for i in range(X.shape[0]):\n",
        "    doc_dict[i] = cosine_similarity(X[i], Query_Bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqAa0mz06bLf"
      },
      "source": [
        "#https://www.quora.com/Which-algorithm-is-used-in-the-python-sort-and-sorted-built-in-functions-and-why\n",
        "# Use in-build sorted function since it uses tim sort which would make use of best of merge sort and insertion sort\n",
        "#https://stackoverflow.com/questions/7197315/5-maximum-values-in-a-python-dictionary\n",
        "a = sorted(doc_dict.items(), key=lambda x: x[1], reverse=True) [:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li3QDqiX6lTP"
      },
      "source": [
        "top_items = []\n",
        "for i in range(10):\n",
        "    top_items.append(a[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40ucId16ocL"
      },
      "source": [
        "for index in top_items:\n",
        "    print (total_df.iloc[index,3])\n",
        "    print(\"*************************************************************************************************************\")\n",
        "    print (total_df.iloc[index,4])\n",
        "    print(\"*************************************************************************************************************\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mguT5R8F6rg4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}