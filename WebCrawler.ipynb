{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wY4z1FZF7ZAt"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import operator\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CDiCqeCe8C-J"
   },
   "outputs": [],
   "source": [
    "Tag_Rank = {}\n",
    "\n",
    "\n",
    "def tag_crawler(url):\n",
    "    source_code = requests.get(url).text\n",
    "    soup = BeautifulSoup(source_code, 'html.parser')\n",
    "    for tag_div in soup.find_all('div', {'class': 'post-taglist'}):\n",
    "        for tag_link in tag_div.find_all('a'):\n",
    "            tag = tag_link.string\n",
    "            if tag in Tag_Rank:\n",
    "                Tag_Rank[tag] += 1\n",
    "            else:\n",
    "                Tag_Rank[tag] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "il_4jwzh8bU1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-9dae2005231f>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if page_no is 1:\n"
     ]
    }
   ],
   "source": [
    "def ques_links_crawler(base_url, end_url, page_limit):\n",
    "    page_no = 1\n",
    "    while page_no <= page_limit:\n",
    "        page_url = base_url + str(page_no) + end_url\n",
    "        source_code = requests.get(page_url).text\n",
    "        soup = BeautifulSoup(source_code, 'html.parser')\n",
    "        if page_no is 1:\n",
    "            os.system('clear')\n",
    "        print('crawling page ' + str(page_no) + ': [', end='')\n",
    "        prev_len = 0\n",
    "        q_no = 1\n",
    "        for ques_link in soup.find_all('a', {'class': 'question-hyperlink'}):\n",
    "            url = 'http://stackoverflow.com/' + ques_link.get('href')\n",
    "            tag_crawler(url)\n",
    "            for _ in range(prev_len):\n",
    "                print('\\b', end='')\n",
    "            print('#', end='')\n",
    "            p_cent = q_no*2\n",
    "            percent = '] (' + str(p_cent) + '%)'\n",
    "            prev_len = len(percent)\n",
    "            print(percent, end='')\n",
    "            sys.stdout.flush()\n",
    "            q_no += 1\n",
    "        page_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ga2FLLsx8eZ_",
    "outputId": "61602b47-042e-4b29-fe08-24d87b119421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter no. of pages to crawl : 1\n",
      "starting crawling...\n",
      "crawling page 1: [#] (2#] (4#] (6#] (8#] (10%#] (12%#] (14%#] (16%#] (18%#] (20%#] (22%#] (24%#] (26%#] (28%#] (30%#] (32%#] (34%#] (36%#] (38%#] (40%#] (42%#] (44%#] (46%#] (48%#] (50%#] (52%#] (54%#] (56%#] (58%#] (60%#] (62%#] (64%#] (66%#] (68%#] (70%#] (72%#] (74%#] (76%#] (78%#] (80%#] (82%#] (84%#] (86%#] (88%#] (90%#] (92%#] (94%#] (96%#] (98%#] (100#] (102#] (104#] (106#] (108#] (110#] (112#] (114#] (116#] (118#] (120#] (122#] (124#] (126#] (128#] (130#] (132#] (134#] (136#] (138#] (140#] (142#] (144#] (146%)\n",
      "Result saved to file Tags_frequency.txt\n"
     ]
    }
   ],
   "source": [
    "def start():\n",
    "    page_limit = int(input('Enter no. of pages to crawl : '))\n",
    "    os.system('clear')\n",
    "    print('starting crawling...')\n",
    "    ques_links_crawler('http://stackoverflow.com/questions?page=', '&sort=newest', page_limit)\n",
    "    fw = open('Tags_frequency3.txt', 'w')\n",
    "    for key, value in sorted(Tag_Rank.items(), key=operator.itemgetter(1), reverse=True):\n",
    "        try:\n",
    "            fw.write(key + \" : \" + str(Tag_Rank[key]) + \"\\n\")\n",
    "        except TypeError:\n",
    "            continue\n",
    "    print('\\nResult saved to file Tags_frequency.txt')\n",
    "\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ls6ZdVrA8hFb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "WebCrawler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
