{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7vl8IeD0bz9",
        "outputId": "09faa2c1-3cd2-4a3f-f444-1b2cab9b67a0"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import math\n",
        "import threading\n",
        "from nltk.corpus import wordnet\n",
        "import time\n",
        "from multiprocessing import Process, Queue\n",
        "import multiprocessing\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import csv \n",
        "import requests \n",
        "import xml.etree.ElementTree as ET \n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "from nltk.stem.porter import *\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool, Manager\n",
        "from datetime import datetime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxBMQydU2Ncu"
      },
      "source": [
        "total_df = pd.read_pickle(\"/content/QuestionsDataSet.pkl\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZSuw84s2TQt"
      },
      "source": [
        "total_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbB10j-l2VqB"
      },
      "source": [
        "for i in range(10):\n",
        "    print(total_df.iloc[i]['Text'])\n",
        "    print(\"=\"*40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n51ZSuo82Yk4"
      },
      "source": [
        "print(total_df['Topic'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMPg8uTY2lrc"
      },
      "source": [
        "posts_text = total_df['Text'].values\n",
        "print(\"Posts_text shape\", posts_text.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "871v5ziY2oEC"
      },
      "source": [
        "posts_text[18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YKHPMTP2qY-"
      },
      "source": [
        "import re\n",
        "#https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
        "def cleanhtml(raw_html):\n",
        "    \"\"\"Remove HTML TAG and convert text to lower case\"\"\"\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHPx-wDi2tIC"
      },
      "source": [
        "preprocessed_post_text = []\n",
        "for i in range(posts_text.shape[0]):\n",
        "    preprocessed_post_text.append(cleanhtml(posts_text[i]))\n",
        "preprocessed_post_text = np.array(preprocessed_post_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk1IGniK2v01"
      },
      "source": [
        "preprocessed_post_text[18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTyt58182zG6"
      },
      "source": [
        "\n",
        "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+';\n",
        "for i in range(preprocessed_post_text.shape[0]):\n",
        "    preprocessed_post_text[i] = re.sub(url_regex, '', preprocessed_post_text[i]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD1W6g1L3E0W"
      },
      "source": [
        "preprocessed_post_text[18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNXTyc9f3IqK"
      },
      "source": [
        "def cleanpunc(sentence): \n",
        "    \"\"\"function to clean the word of any punctuation or special characters\"\"\"\n",
        "    cleaned = re.sub(r'[?|!|\"|#|:|=|+|_|{|}|[|]|-|$|%|^|&|]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/|-|~|`|>|<|*|$|@|;|â†’]',r'',cleaned)\n",
        "    return  cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut9viXa93Let"
      },
      "source": [
        "\n",
        "for i in range(preprocessed_post_text.shape[0]):\n",
        "    preprocessed_post_text[i] = cleanpunc(preprocessed_post_text[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKRjoskD3Ns3"
      },
      "source": [
        "preprocessed_post_text[18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3WAolJ13Qy1"
      },
      "source": [
        "import re\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python same code snippet from assignment as well\n",
        "    \"\"\" expanding and creating common English contractions in text\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    phrase = re.sub(r\"\\n\", \"\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ce_6fy3Ti1"
      },
      "source": [
        "for i in range(preprocessed_post_text.shape[0]):\n",
        "    preprocessed_post_text[i] = decontracted(preprocessed_post_text[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O0TcOzO3mBc"
      },
      "source": [
        "\n",
        "non_stop_word_removed_posts = preprocessed_post_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLyGQU0w3pJ6"
      },
      "source": [
        "non_stop_word_removed_posts[18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W9HEUlC3qxT"
      },
      "source": [
        "\n",
        "non_stop_word_removed_posts_df = pd.DataFrame(non_stop_word_removed_posts, columns=['non_stopword_removed_preprocessed_text'])\n",
        "non_stop_word_removed_posts_df.index = total_df.index\n",
        "non_stop_word_removed_posts_df['Id'] = total_df['Id']\n",
        "total_df = total_df.merge(non_stop_word_removed_posts_df, on='Id',how='left')\n",
        "total_df.to_pickle('non_stop_word_removed_posts.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nRgYtNK4NxJ"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print ('list of stop words:', stop_words)\n",
        "\n",
        "def nlp_preprocessing(total_text):\n",
        "    \"\"\"Removes stop words and alpha numeric values\"\"\"\n",
        "    if type(total_text) is not int:# Numbers doesn't make any sense in searching them\n",
        "        string = \"\"\n",
        "        for words in total_text.split():\n",
        "            # remove the special chars in review like '\"#$@!%^&*()_+-~?>< etc.\n",
        "            word = (\"\".join(e for e in words if e.isalnum()))\n",
        "            # stop-word removal\n",
        "            if not word in stop_words:\n",
        "                string += word + \" \"\n",
        "        return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VZCllTU4UW_"
      },
      "source": [
        "mport time\n",
        "start_time = time.clock()\n",
        "# we take each title and we text-preprocess it.\n",
        "for i in range(preprocessed_post_text.shape[0]):\n",
        "    preprocessed_post_text[i] = nlp_preprocessing(preprocessed_post_text[i], i)\n",
        "# we print the time it took to preprocess whole titles \n",
        "print(time.clock() - start_time, \"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olcKYLku4aG7"
      },
      "source": [
        "preprocessed_post_text[18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OuIDNqH4dOv"
      },
      "source": [
        "preprocesses_text_df = pd.DataFrame(preprocessed_post_text, columns=['preprocessed_text'])\n",
        "preprocesses_text_df.index = total_df.index\n",
        "preprocesses_text_df['Id'] = total_df['Id']\n",
        "total_df = total_df.merge(preprocesses_text_df, on='Id',how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "casU4HG14fy9"
      },
      "source": [
        "print(\"Shape\", total_df.shape)\n",
        "total_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxtxQX-24iKG"
      },
      "source": [
        "total_df = total_df[total_df['preprocessed_text'] != '']\n",
        "total_df = total_df[total_df['preprocessed_text'] != ' ']\n",
        "total_df = total_df.reset_index(drop=True)\n",
        "total_df.to_pickle('Preprocessed_questions_text.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wJZ35sd4lW6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}