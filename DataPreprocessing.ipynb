{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7vl8IeD0bz9",
    "outputId": "09faa2c1-3cd2-4a3f-f444-1b2cab9b67a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SAI\n",
      "[nltk_data]     DEEPTHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import threading\n",
    "from nltk.corpus import wordnet\n",
    "import time\n",
    "from multiprocessing import Process, Queue\n",
    "import multiprocessing\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import csv \n",
    "import requests \n",
    "import xml.etree.ElementTree as ET \n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "from nltk.stem.porter import *\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, Manager\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sxBMQydU2Ncu"
   },
   "outputs": [],
   "source": [
    "total_df = pd.read_pickle(\"QuestionsDataSet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kZSuw84s2TQt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Besides being \"one of the 7 meta questions ...</td>\n",
       "      <td>/AImeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I've clicked on &lt;em&gt;chat&lt;/em&gt; link, but the...</td>\n",
       "      <td>/AImeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I think this will be a crucial thing to fig...</td>\n",
       "      <td>/AImeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Are all questions asked on stats and data s...</td>\n",
       "      <td>/AImeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;I've seen several questions that use the &lt;a...</td>\n",
       "      <td>/AImeta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id                                               Text    Topic\n",
       "0  0  <p>Besides being \"one of the 7 meta questions ...  /AImeta\n",
       "1  1  <p>I've clicked on <em>chat</em> link, but the...  /AImeta\n",
       "2  2  <p>I think this will be a crucial thing to fig...  /AImeta\n",
       "3  3  <p>Are all questions asked on stats and data s...  /AImeta\n",
       "4  4  <p>I've seen several questions that use the <a...  /AImeta"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbB10j-l2VqB"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(total_df.iloc[i]['Text'])\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n51ZSuo82Yk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/AImeta' '/AI' '/ComputerGraphicsMeta' '/ComputerGraphics' '/CSMeta'\n",
      " '/CS' '/DataScienceMeta' '/DataScience']\n"
     ]
    }
   ],
   "source": [
    "print(total_df['Topic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MMPg8uTY2lrc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts_text shape (161423,)\n"
     ]
    }
   ],
   "source": [
    "posts_text = total_df['Text'].values\n",
    "print(\"Posts_text shape\", posts_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "871v5ziY2oEC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><strong>Yes</strong></p>\\r\\n\\r\\n<p>I am sorry to be the one who posts Yes, but as we are in the beta, I want to be straight forward.</p>\\r\\n\\r\\n<p>In addition to that, AI is also on-topic in the CS site. <a href=\"https://area51.meta.stackexchange.com/q/22939/142759\">I was the one who raised this in the definition phase</a>.</p>\\r\\n\\r\\n<p>So, a lot of topic which this site aims to cover are already covered in the existing sites.</p>\\r\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_text[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7YKHPMTP2qY-"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "def cleanhtml(raw_html):\n",
    "    \"\"\"Remove HTML TAG and convert text to lower case\"\"\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gHPx-wDi2tIC"
   },
   "outputs": [],
   "source": [
    "preprocessed_post_text = []\n",
    "for i in range(posts_text.shape[0]):\n",
    "    preprocessed_post_text.append(cleanhtml(posts_text[i]))\n",
    "preprocessed_post_text = np.array(preprocessed_post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sk1IGniK2v01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes\\r\\n\\r\\ni am sorry to be the one who posts yes, but as we are in the beta, i want to be straight forward.\\r\\n\\r\\nin addition to that, ai is also on-topic in the cs site. i was the one who raised this in the definition phase.\\r\\n\\r\\nso, a lot of topic which this site aims to cover are already covered in the existing sites.\\r\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_post_text[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTyt58182zG6"
   },
   "outputs": [],
   "source": [
    "\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+';\n",
    "for i in range(preprocessed_post_text.shape[0]):\n",
    "    preprocessed_post_text[i] = re.sub(url_regex, '', preprocessed_post_text[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iD1W6g1L3E0W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes\\r\\n\\r\\ni am sorry to be the one who posts yes, but as we are in the beta, i want to be straight forward.\\r\\n\\r\\nin addition to that, ai is also on-topic in the cs site. i was the one who raised this in the definition phase.\\r\\n\\r\\nso, a lot of topic which this site aims to cover are already covered in the existing sites.\\r\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_post_text[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sNXTyc9f3IqK"
   },
   "outputs": [],
   "source": [
    "def cleanpunc(sentence): \n",
    "    \"\"\"function to clean the word of any punctuation or special characters\"\"\"\n",
    "    cleaned = re.sub(r'[?|!|\"|#|:|=|+|_|{|}|[|]|-|$|%|^|&|]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/|-|~|`|>|<|*|$|@|;|â†’]',r'',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut9viXa93Let"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(preprocessed_post_text.shape[0]):\n",
    "    preprocessed_post_text[i] = cleanpunc(preprocessed_post_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JKRjoskD3Ns3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes\\r\\n\\r\\ni am sorry to be the one who posts yes but as we are in the beta i want to be straight forward\\r\\n\\r\\nin addition to that ai is also ontopic in the cs site i was the one who raised this in the definition phase\\r\\n\\r\\nso a lot of topic which this site aims to cover are already covered in the existing sites\\r\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_post_text[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m3WAolJ13Qy1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python same code snippet from assignment as well\n",
    "    \"\"\" expanding and creating common English contractions in text\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"\\n\", \"\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "04ce_6fy3Ti1"
   },
   "outputs": [],
   "source": [
    "for i in range(preprocessed_post_text.shape[0]):\n",
    "    preprocessed_post_text[i] = decontracted(preprocessed_post_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7O0TcOzO3mBc"
   },
   "outputs": [],
   "source": [
    "\n",
    "non_stop_word_removed_posts = preprocessed_post_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eLyGQU0w3pJ6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes\\r\\ri am sorry to be the one who posts yes but as we are in the beta i want to be straight forward\\r\\rin addition to that ai is also ontopic in the cs site i was the one who raised this in the definition phase\\r\\rso a lot of topic which this site aims to cover are already covered in the existing sites\\r'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_stop_word_removed_posts[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9W9HEUlC3qxT"
   },
   "outputs": [],
   "source": [
    "\n",
    "non_stop_word_removed_posts_df = pd.DataFrame(non_stop_word_removed_posts, columns=['non_stopword_removed_preprocessed_text'])\n",
    "non_stop_word_removed_posts_df.index = total_df.index\n",
    "non_stop_word_removed_posts_df['Id'] = total_df['Id']\n",
    "total_df = total_df.merge(non_stop_word_removed_posts_df, on='Id',how='left')\n",
    "total_df.to_pickle('non_stop_word_removed_posts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7nRgYtNK4NxJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of stop words: {'shouldn', 'of', 'their', 'is', 'between', 'by', 'against', 'than', 'has', 'all', 'just', \"doesn't\", \"won't\", 'those', 'needn', 'why', 'been', 'isn', 'i', 'at', 'such', 'above', 'down', 'on', 'hers', 'o', 'hasn', 'which', 'mightn', 'other', 'few', 'won', 'to', 't', \"isn't\", 'once', \"wouldn't\", 'who', \"she's\", 'more', 'couldn', 'her', 'd', 'your', 'nor', 'doing', 'too', 'they', 'did', 'doesn', 'weren', 'himself', 'as', \"you'd\", 'there', 're', 'ourselves', 'herself', 'don', 'about', 'these', 'y', 'through', 'only', 'how', 'can', 'mustn', 'wouldn', \"aren't\", 'some', 'the', 'aren', 'from', 'ours', 'again', 'further', 'does', 'own', \"that'll\", 'myself', 'themselves', 'when', \"should've\", 'or', 'were', 'was', 'had', 'wasn', 'shan', \"couldn't\", \"wasn't\", 'didn', 'being', 'that', 'yours', 'you', 'he', 'before', 'his', \"haven't\", 'him', 'each', 'most', \"shouldn't\", \"weren't\", 'and', 'an', 'no', 'm', 'ain', \"you're\", \"mightn't\", 'its', \"didn't\", 'me', 'ma', 'them', 'then', 'what', 'itself', 'having', 'until', 'she', 'below', 'into', 'here', \"you'll\", 'if', 'so', 'for', \"you've\", 'both', 'it', 'do', 'yourself', 'but', 'same', 'have', \"hasn't\", 'off', 's', 'should', 'a', 'we', 'our', 'while', \"don't\", 'this', 'yourselves', 'up', 'because', 'during', 've', 'am', 'are', \"hadn't\", 'with', 'not', 'theirs', 'under', 'll', \"it's\", 'out', 'where', 'my', 'in', 'haven', \"needn't\", \"mustn't\", 'now', 'be', 'very', 'hadn', 'after', \"shan't\", 'any', 'over', 'will', 'whom'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print ('list of stop words:', stop_words)\n",
    "\n",
    "def nlp_preprocessing(total_text):\n",
    "    \"\"\"Removes stop words and alpha numeric values\"\"\"\n",
    "    if type(total_text) is not int:# Numbers doesn't make any sense in searching them\n",
    "        string = \"\"\n",
    "        for words in total_text.split():\n",
    "            # remove the special chars in review like '\"#$@!%^&*()_+-~?>< etc.\n",
    "            word = (\"\".join(e for e in words if e.isalnum()))\n",
    "            # stop-word removal\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1VZCllTU4UW_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# we take each title and we text-preprocess it.\n",
    "for i in range(preprocessed_post_text.shape[0]):\n",
    "    preprocessed_post_text[i] = nlp_preprocessing(preprocessed_post_text[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "olcKYLku4aG7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes sorry one posts yes beta want straight forward addition ai also ontopic cs site one raised definition phase lot topic site aims cover already covered existing sites '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_post_text[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8OuIDNqH4dOv"
   },
   "outputs": [],
   "source": [
    "preprocesses_text_df = pd.DataFrame(preprocessed_post_text, columns=['preprocessed_text'])\n",
    "preprocesses_text_df.index = total_df.index\n",
    "preprocesses_text_df['Id'] = total_df['Id']\n",
    "total_df = total_df.merge(preprocesses_text_df, on='Id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "casU4HG14fy9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (161423, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>non_stopword_removed_preprocessed_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Besides being \"one of the 7 meta questions ...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>besides being one of the 7 meta questions ever...</td>\n",
       "      <td>besides one 7 meta questions every site ask pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I've clicked on &lt;em&gt;chat&lt;/em&gt; link, but the...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>i have clicked on chat link but the list is em...</td>\n",
       "      <td>clicked chat link list empty also tried create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I think this will be a crucial thing to fig...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>i think this will be a crucial thing to figure...</td>\n",
       "      <td>think crucial thing figure one hand think impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Are all questions asked on stats and data s...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>are all questions asked on stats and data scie...</td>\n",
       "      <td>questions asked stats data science se also top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;I've seen several questions that use the &lt;a...</td>\n",
       "      <td>/AImeta</td>\n",
       "      <td>i have seen several questions that use the art...</td>\n",
       "      <td>seen several questions use artificialintellige...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id                                               Text    Topic  \\\n",
       "0  0  <p>Besides being \"one of the 7 meta questions ...  /AImeta   \n",
       "1  1  <p>I've clicked on <em>chat</em> link, but the...  /AImeta   \n",
       "2  2  <p>I think this will be a crucial thing to fig...  /AImeta   \n",
       "3  3  <p>Are all questions asked on stats and data s...  /AImeta   \n",
       "4  4  <p>I've seen several questions that use the <a...  /AImeta   \n",
       "\n",
       "              non_stopword_removed_preprocessed_text  \\\n",
       "0  besides being one of the 7 meta questions ever...   \n",
       "1  i have clicked on chat link but the list is em...   \n",
       "2  i think this will be a crucial thing to figure...   \n",
       "3  are all questions asked on stats and data scie...   \n",
       "4  i have seen several questions that use the art...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  besides one 7 meta questions every site ask pl...  \n",
       "1  clicked chat link list empty also tried create...  \n",
       "2  think crucial thing figure one hand think impo...  \n",
       "3  questions asked stats data science se also top...  \n",
       "4  seen several questions use artificialintellige...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape\", total_df.shape)\n",
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "CxtxQX-24iKG"
   },
   "outputs": [],
   "source": [
    "total_df = total_df[total_df['preprocessed_text'] != '']\n",
    "total_df = total_df[total_df['preprocessed_text'] != ' ']\n",
    "total_df = total_df.reset_index(drop=True)\n",
    "total_df.to_pickle('Preprocessed_questions_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DataPreprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
