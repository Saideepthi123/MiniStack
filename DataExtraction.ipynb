{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQTwme3V9SGZ",
    "outputId": "23351388-fcc2-46c9-9b7f-049a17e2fe5f"
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "import requests \n",
    "import xml.etree.ElementTree as ET \n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing XML files\n",
    "This function would parse XML file and would extract important information from xml tag 'body' \n",
    "    and returns list containing dict whcih would have text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YEBYjv_B-n3R"
   },
   "outputs": [],
   "source": [
    "fields = ['Id', 'Text', 'Topic']\n",
    "\n",
    "def parseXML(xmlfile, start_count): \n",
    "    #create element tree object \n",
    "    print(\"File\", xmlfile)\n",
    "    tree = ET.parse(xmlfile) # Creates a parse tree \n",
    "    topic = xmlfile.split(\"XML-Files\")[1].split(\"_\")[0] # Getting xml file_name from string containing directory/file_name.xml \n",
    "    # get root element using which we would parse xml tree\n",
    "    root = tree.getroot() \n",
    "    # create empty list for news items \n",
    "    newsitems = [] \n",
    "    count = start_count\n",
    "    # iterate news items \n",
    "    for each_row in root.iter(\"row\"):#  iterates only over those elements that have the required tag:\"row\" \n",
    "        news = {}\n",
    "        news[\"Id\"] = count\n",
    "        news[\"Text\"] = each_row.attrib[\"Body\"]\n",
    "        news[\"Topic\"] = topic\n",
    "        count=count+1\n",
    "        newsitems.append(news) #[{id:1,text:\" Some text  \",Topic : \"AI\"},{{id:1,text:\" Some text  \",Topic : \"AI\"},...........]\n",
    "    # return news items list \n",
    "    print(\"len\", len(newsitems))\n",
    "    return newsitems # To save this dict on csv we are putting dict into a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving in Csv files\n",
    "Writes the list of dict returned from above function onto a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DCGPZAtQ-8XY"
   },
   "outputs": [],
   "source": [
    "def savetoCSV(newsitems, filename): \n",
    "    # writing to csv file \n",
    "    with open(filename, 'w', encoding = 'utf-8') as csvfile: \n",
    "        # creating a csv dict writer object \n",
    "        writer = csv.DictWriter(csvfile, fieldnames = fields) \n",
    "        # writing headers (field names) \n",
    "        writer.writeheader() \n",
    "        # writing data rows \n",
    "        writer.writerows(newsitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHWWqdvR_P7Y",
    "outputId": "bc88f40c-579d-4a37-d271-a681c73830ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AImeta_Posts.xml\n",
      "File XML-Files/AImeta_Posts.xml\n",
      "len 654\n",
      "csv_filename AImeta_Posts.csv\n",
      "AI_Posts.xml\n",
      "File XML-Files/AI_Posts.xml\n",
      "len 16760\n",
      "csv_filename AI_Posts.csv\n",
      "ComputerGraphicsMeta_Posts.xml\n",
      "File XML-Files/ComputerGraphicsMeta_Posts.xml\n",
      "len 299\n",
      "csv_filename ComputerGraphicsMeta_Posts.csv\n",
      "ComputerGraphics_Posts.xml\n",
      "File XML-Files/ComputerGraphics_Posts.xml\n",
      "len 6070\n",
      "csv_filename ComputerGraphics_Posts.csv\n",
      "CSMeta_Posts.xml\n",
      "File XML-Files/CSMeta_Posts.xml\n",
      "len 1585\n",
      "csv_filename CSMeta_Posts.csv\n",
      "CS_Posts.xml\n",
      "File XML-Files/CS_Posts.xml\n",
      "len 81429\n",
      "csv_filename CS_Posts.csv\n",
      "DataScienceMeta_Posts.xml\n",
      "File XML-Files/DataScienceMeta_Posts.xml\n",
      "len 509\n",
      "csv_filename DataScienceMeta_Posts.csv\n",
      "DataScience_Posts.xml\n",
      "File XML-Files/DataScience_Posts.xml\n",
      "len 54869\n",
      "csv_filename DataScience_Posts.csv\n"
     ]
    }
   ],
   "source": [
    "def filterpostfiles(filename):\n",
    "    \"\"\"Returns the name of  xml files present in the directory CML Files \"\"\"\n",
    "    return filename.endswith(\"Posts.xml\") \n",
    "postfiles = filter(filterpostfiles, os.listdir(\"XML-Files\"))\n",
    "\n",
    "# specifying the fields for csv file \n",
    "fields = ['Id', 'Text', 'Topic']  \n",
    "start_count = 0\n",
    "for each_file in postfiles:\n",
    "    print(each_file)\n",
    "    # parse xml file \n",
    "    newsitems = parseXML(\"XML-Files/\"+each_file, start_count)\n",
    "    #Get only name of xml file by sepearting out extension use the same name to save file as .csv \n",
    "    csv_filename = each_file.split('.')[0] + \".csv\"\n",
    "    print(\"csv_filename\", csv_filename)\n",
    "    # store news items in a csv file \n",
    "    savetoCSV(newsitems, \"CSV-Files/\" + csv_filename)\n",
    "    start_count = len(newsitems) + start_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KfpcyNWE_TGU"
   },
   "outputs": [],
   "source": [
    "def filtercsvpostfiles(filename):\n",
    "    \"\"\" Returns all the csv file name extracted from XML which are stored in CSV files\"\"\"\n",
    "    return filename.endswith(\"Posts.csv\") \n",
    "csvpostfiles = filter(filtercsvpostfiles, os.listdir(\"CSV-Files\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging All the csv files into one single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE59DBqkzYMi",
    "outputId": "bd8b9d9a-c809-4d4b-bcda-e4cc543682fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each file AImeta_Posts.csv\n",
      "shape (654, 3)\n",
      "each file AI_Posts.csv\n",
      "shape (16760, 3)\n",
      "each file ComputerGraphicsMeta_Posts.csv\n",
      "shape (299, 3)\n",
      "each file ComputerGraphics_Posts.csv\n",
      "shape (6070, 3)\n",
      "each file CSMeta_Posts.csv\n",
      "shape (1585, 3)\n",
      "each file CS_Posts.csv\n",
      "shape (81429, 3)\n",
      "each file DataScienceMeta_Posts.csv\n",
      "shape (509, 3)\n",
      "each file DataScience_Posts.csv\n",
      "shape (54869, 3)\n"
     ]
    }
   ],
   "source": [
    "total_dataframe = pd.DataFrame(columns=fields)\n",
    "for each_file in csvpostfiles:\n",
    "    print(\"each file\", each_file)\n",
    "    df = pd.read_csv(\"CSV-Files/\"+ each_file)\n",
    "    print(\"shape\", df.shape)\n",
    "    total_dataframe = total_dataframe.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLxsdEjFzi1R",
    "outputId": "52d9d3a9-613b-433d-d2d5-03b43414aba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of total dataframe (162175, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of total dataframe\", total_dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZruxdnRIzlWb",
    "outputId": "340c61bc-2b50-4f7a-a633-ddeea5a9a410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of total dataframe after null value remove (161423, 3)\n"
     ]
    }
   ],
   "source": [
    "total_dataframe = total_dataframe[~total_dataframe['Text'].isna()]\n",
    "total_dataframe = total_dataframe[~total_dataframe['Text'].isnull()]\n",
    "print(\"Shape of total dataframe after null value remove\", total_dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved the required form of data in QuestionsDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "3SasvvvWzneq",
    "outputId": "94e51dc0-f2d7-42e4-afdb-b4250d02c94a"
   },
   "outputs": [],
   "source": [
    "\n",
    "total_dataframe.to_pickle(\"QuestionsDataSet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dyHLOEF8zpoW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DataExtraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
