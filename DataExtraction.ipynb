{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataExtraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQTwme3V9SGZ",
        "outputId": "23351388-fcc2-46c9-9b7f-049a17e2fe5f"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import math\n",
        "import threading\n",
        "from nltk.corpus import wordnet\n",
        "import time\n",
        "from multiprocessing import Process, Queue\n",
        "import multiprocessing\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import csv \n",
        "import requests \n",
        "import xml.etree.ElementTree as ET \n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "from nltk.stem.porter import *\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool, Manager\n",
        "from datetime import datetime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdBRHpGu9kSy",
        "outputId": "3b888224-1df3-4d4a-9242-cc9c03329b21"
      },
      "source": [
        "!unzip XML-Files.zip -d XML-Files"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  XML-Files.zip\n",
            "  inflating: XML-Files/XML-Files/AI_Meta_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/AI_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/Computer_graphics_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/Computergraphics_Meta_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/CS_Meta_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/CS_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/DataScience_Meta_Posts.xml  \n",
            "  inflating: XML-Files/XML-Files/DataScience_Posts.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEBYjv_B-n3R"
      },
      "source": [
        "fields = ['Id', 'Text', 'Topic']\n",
        "\n",
        "def parseXML(xmlfile, start_count): \n",
        "    \"\"\"This function would parse XML file and would extract important information from xml tag 'text' \n",
        "    and returns list containing dict whcih would have text\"\"\"\n",
        "    #https://www.geeksforgeeks.org/xml-parsing-python/\n",
        "    #create element tree object \n",
        "    print(\"File\", xmlfile)\n",
        "    tree = ET.parse(xmlfile) # Creates a parse tree like https://www.google.com/search?q=xml+parse+tree&sxsrf=ALeKk00rw2XjRSAi-qGfaA0Rg4EtJzyx_Q:1585918970675&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi0wY7HqMzoAhVXAXIKHYfdDrkQ_AUoAXoECA4QAw&biw=1366&bih=657#imgrc=P4mJt0kjVEuqVM\n",
        "    topic = xmlfile.split(\"/content/XML-Files\")[1].split(\"_\")[0] # Getting xml file_name from string containing directory/file_name.xml \n",
        "    # get root element using which we would parse xml tree\n",
        "    root = tree.getroot() \n",
        "    # create empty list for news items \n",
        "    newsitems = [] \n",
        "    count = start_count\n",
        "    # iterate news items \n",
        "    for each_row in root.iter(\"row\"):#  iterates only over those elements that have the required tag:\"row\" \n",
        "        news = {}\n",
        "        news[\"Id\"] = count\n",
        "        news[\"Text\"] = each_row.attrib[\"Body\"]\n",
        "        news[\"Topic\"] = topic\n",
        "        count=count+1\n",
        "        newsitems.append(news) #[{id:1,text:\" Some text  \",Topic : \"AI\"},{{id:1,text:\" Some text  \",Topic : \"AI\"},{{id:1,text:\" Some text  \",Topic : \"AI\"},...........]\n",
        "    # return news items list \n",
        "    print(\"len\", len(newsitems))\n",
        "    return newsitems # To save this dict on csv we are putting dict into a list https://www.tutorialspoint.com/How-to-save-a-Python-Dictionary-to-CSV-file"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCGPZAtQ-8XY"
      },
      "source": [
        "def savetoCSV(newsitems, filename): \n",
        "    \"\"\"Writes the list of dict returned from above function onto a csv file\"\"\" \n",
        "    # writing to csv file \n",
        "    with open(filename, 'w', encoding = 'utf-8') as csvfile: \n",
        "        # creating a csv dict writer object \n",
        "        writer = csv.DictWriter(csvfile, fieldnames = fields) \n",
        "        # writing headers (field names) \n",
        "        writer.writeheader() \n",
        "        # writing data rows \n",
        "        writer.writerows(newsitems)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHWWqdvR_P7Y",
        "outputId": "bc88f40c-579d-4a37-d271-a681c73830ae"
      },
      "source": [
        "def filterpostfiles(filename):\n",
        "    \"\"\"Returns the name of  xml files present in the directory CML Files \"\"\"\n",
        "    return filename.endswith(\"Posts.xml\") \n",
        "postfiles = filter(filterpostfiles, os.listdir(\"/content/XML-Files\"))\n",
        "\n",
        "# specifying the fields for csv file \n",
        "fields = ['Id', 'Text', 'Topic']  \n",
        "start_count = 0\n",
        "for each_file in postfiles:\n",
        "    print(each_file)\n",
        "    # parse xml file \n",
        "    newsitems = parseXML(\"/content/XML-Files/\"+each_file, start_count)\n",
        "    #Get only name of xml file by sepearting out extension use the same name to save file as .csv \n",
        "    csv_filename = each_file.split('.')[0] + \".csv\"\n",
        "    print(\"csv_filename\", csv_filename)\n",
        "    # store news items in a csv file \n",
        "    savetoCSV(newsitems, \"/content/CSV-Files/\" + csv_filename)\n",
        "    start_count = len(newsitems) + start_count"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataScience_Posts.xml\n",
            "File /content/XML-Files/DataScience_Posts.xml\n",
            "len 54869\n",
            "csv_filename DataScience_Posts.csv\n",
            "CS_Posts.xml\n",
            "File /content/XML-Files/CS_Posts.xml\n",
            "len 81429\n",
            "csv_filename CS_Posts.csv\n",
            "AI_Posts.xml\n",
            "File /content/XML-Files/AI_Posts.xml\n",
            "len 16760\n",
            "csv_filename AI_Posts.csv\n",
            "AI_Meta_Posts.xml\n",
            "File /content/XML-Files/AI_Meta_Posts.xml\n",
            "len 654\n",
            "csv_filename AI_Meta_Posts.csv\n",
            "CS_Meta_Posts.xml\n",
            "File /content/XML-Files/CS_Meta_Posts.xml\n",
            "len 1585\n",
            "csv_filename CS_Meta_Posts.csv\n",
            "Computer_graphics_Posts.xml\n",
            "File /content/XML-Files/Computer_graphics_Posts.xml\n",
            "len 6070\n",
            "csv_filename Computer_graphics_Posts.csv\n",
            "Computergraphics_Meta_Posts.xml\n",
            "File /content/XML-Files/Computergraphics_Meta_Posts.xml\n",
            "len 299\n",
            "csv_filename Computergraphics_Meta_Posts.csv\n",
            "DataScience_Meta_Posts.xml\n",
            "File /content/XML-Files/DataScience_Meta_Posts.xml\n",
            "len 509\n",
            "csv_filename DataScience_Meta_Posts.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpcyNWE_TGU"
      },
      "source": [
        "def filtercsvpostfiles(filename):\n",
        "    \"\"\" Returns all the csv file name extracted from XML which are stored in CSV files\"\"\"\n",
        "    return filename.endswith(\"Posts.csv\") \n",
        "csvpostfiles = filter(filtercsvpostfiles, os.listdir(\"CSV-Files\"))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE59DBqkzYMi",
        "outputId": "bd8b9d9a-c809-4d4b-bcda-e4cc543682fd"
      },
      "source": [
        "\n",
        "total_dataframe = pd.DataFrame(columns=fields)\n",
        "for each_file in csvpostfiles:\n",
        "    #Merge multiple csv file created from each xml file into just one xml file\n",
        "    print(\"each file\", each_file)\n",
        "    df = pd.read_csv(\"CSV-Files/\"+ each_file)\n",
        "    print(\"shape\", df.shape)\n",
        "    total_dataframe = total_dataframe.append(df, ignore_index=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "each file CS_Meta_Posts.csv\n",
            "shape (1585, 3)\n",
            "each file AI_Posts.csv\n",
            "shape (16760, 3)\n",
            "each file DataScience_Meta_Posts.csv\n",
            "shape (509, 3)\n",
            "each file Computergraphics_Meta_Posts.csv\n",
            "shape (299, 3)\n",
            "each file AI_Meta_Posts.csv\n",
            "shape (654, 3)\n",
            "each file Computer_graphics_Posts.csv\n",
            "shape (6070, 3)\n",
            "each file CS_Posts.csv\n",
            "shape (81429, 3)\n",
            "each file DataScience_Posts.csv\n",
            "shape (54869, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLxsdEjFzi1R",
        "outputId": "52d9d3a9-613b-433d-d2d5-03b43414aba0"
      },
      "source": [
        "\n",
        "print(\"Shape of total dataframe\", total_dataframe.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of total dataframe (162175, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZruxdnRIzlWb",
        "outputId": "340c61bc-2b50-4f7a-a633-ddeea5a9a410"
      },
      "source": [
        "total_dataframe = total_dataframe[~total_dataframe['Text'].isna()]\n",
        "total_dataframe = total_dataframe[~total_dataframe['Text'].isnull()]\n",
        "print(\"Shape of total dataframe after null value remove\", total_dataframe.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of total dataframe after null value remove (161423, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "3SasvvvWzneq",
        "outputId": "94e51dc0-f2d7-42e4-afdb-b4250d02c94a"
      },
      "source": [
        "\n",
        "total_dataframe.to_pickle(\"QuestionsDataSet.pkl\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b648dc0d66d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"QuestionsDataSet.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'total_dataframe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyHLOEF8zpoW"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykTuzE7z0qG0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqkIDavD0x6L"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OemU_wqY00_M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6BqMBf0358"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqnLVOYJ07xZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh8sWFu01bAc"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQqw3HoO1iVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S18Xognt1k0F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}